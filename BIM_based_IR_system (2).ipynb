{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from math import log\n"
      ],
      "metadata": {
        "id": "muRIDucxK_t4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function\n",
        "def preprocess(text):\n",
        "    return re.findall(r'\\b\\w+\\b', text.lower())\n"
      ],
      "metadata": {
        "id": "6q6klgEqLB0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load documents\n",
        "def load_documents(folder_path):\n",
        "    docs = {}\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('.txt'):\n",
        "            with open(os.path.join(folder_path, filename), 'r') as file:\n",
        "                docs[filename] = preprocess(file.read())\n",
        "    return docs\n"
      ],
      "metadata": {
        "id": "Fzq0xK1ELExV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load queries\n",
        "def load_queries(query_file_path):\n",
        "    with open(query_file_path, 'r') as file:\n",
        "        return [line.strip() for line in file.readlines()]\n"
      ],
      "metadata": {
        "id": "QJpzM5L2LH_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute term frequencies and document frequencies\n",
        "def compute_statistics(docs):\n",
        "    doc_count = len(docs)\n",
        "    term_doc_freq = defaultdict(int)\n",
        "    term_freq = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    for doc_id, words in docs.items():\n",
        "        word_set = set(words)\n",
        "        for word in words:\n",
        "            term_freq[doc_id][word] += 1\n",
        "        for word in word_set:\n",
        "            term_doc_freq[word] += 1\n",
        "\n",
        "    return term_freq, term_doc_freq, doc_count"
      ],
      "metadata": {
        "id": "esKGI2lnLZZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute relevance probabilities using BIM\n",
        "def compute_relevance_prob(query, term_freq, term_doc_freq, doc_count):\n",
        "    scores = {}\n",
        "    for doc_id in term_freq:\n",
        "        score = 1.0\n",
        "        for term in query:\n",
        "            tf = term_freq[doc_id].get(term, 0)\n",
        "            df = term_doc_freq.get(term, 0)\n",
        "            p_term_given_relevant = (tf + 1) / (sum(term_freq[doc_id].values()) + len(term_doc_freq))\n",
        "            p_term_given_not_relevant = (df + 1) / (doc_count - df + len(term_doc_freq))\n",
        "            score *= (p_term_given_relevant / p_term_given_not_relevant)\n",
        "        scores[doc_id] = score\n",
        "    return scores"
      ],
      "metadata": {
        "id": "u04gsli_Lelc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Main retrieval function\n",
        "def retrieve_documents(folder_path, query_file_path):\n",
        "    docs = load_documents(folder_path)\n",
        "    queries = load_queries(query_file_path)\n",
        "\n",
        "    term_freq, term_doc_freq, doc_count = compute_statistics(docs)\n",
        "\n",
        "    # Define the output file path in the same directory as the dataset folder\n",
        "    output_file_path = os.path.join(folder_path, 'Prahar_result.txt')\n",
        "\n",
        "    # Open a file to write results in the same directory as the dataset\n",
        "    with open(output_file_path, 'w') as result_file:\n",
        "        for query in queries:\n",
        "            query_terms = preprocess(query)\n",
        "            scores = compute_relevance_prob(query_terms, term_freq, term_doc_freq, doc_count)\n",
        "            ranked_docs = sorted(scores.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "            # Print to console and write to file\n",
        "            print(f\"Query: {query}\")\n",
        "            result_file.write(f\"Query: {query}\\n\")\n",
        "\n",
        "            # Print and write only the top 3 results with ranks\n",
        "            for rank, (doc_id, score) in enumerate(ranked_docs[:3], start=1):\n",
        "                print(f\"Rank {rank}: Document {doc_id}, Score: {score:.4f}\")\n",
        "                result_file.write(f\"Rank {rank}: Document {doc_id}, Score: {score:.4f}\\n\")\n",
        "\n",
        "            print()\n",
        "            result_file.write(\"\\n\")\n",
        "\n",
        "# Example usage\n",
        "folder_path = '/content/drive/MyDrive/Information Retrieval System/Week4/docs'\n",
        "query_file_path = '/content/drive/MyDrive/Information Retrieval System/Week4/queries.txt'\n",
        "retrieve_documents(folder_path, query_file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7EO32CGb4P6",
        "outputId": "c8275dff-25ed-406d-fe8a-70242f3f5508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: iPhone battery drain\n",
            "Rank 1: Document Docs1.txt, Score: 0.3582\n",
            "Rank 2: Document Docs18.txt, Score: 0.2107\n",
            "Rank 3: Document Docs17.txt, Score: 0.1050\n",
            "\n",
            "Query: Spotify Bluetooth issue\n",
            "Rank 1: Document Docs18.txt, Score: 0.0618\n",
            "Rank 2: Document Docs10.txt, Score: 0.0388\n",
            "Rank 3: Document Docs2.txt, Score: 0.0354\n",
            "\n",
            "Query: Train delay update\n",
            "Rank 1: Document Docs5.txt, Score: 0.1876\n",
            "Rank 2: Document Docs19.txt, Score: 0.1783\n",
            "Rank 3: Document Docs7.txt, Score: 0.1479\n",
            "\n",
            "Query: O2 telemarketing calls\n",
            "Rank 1: Document Docs17.txt, Score: 0.8420\n",
            "Rank 2: Document Docs18.txt, Score: 0.4226\n",
            "Rank 3: Document Docs19.txt, Score: 0.4194\n",
            "\n",
            "Query: iOS downgrade\n",
            "Rank 1: Document Docs1.txt, Score: 1.5297\n",
            "Rank 2: Document Docs18.txt, Score: 0.4468\n",
            "Rank 3: Document Docs17.txt, Score: 0.4457\n",
            "\n",
            "Query: British Airways delay\n",
            "Rank 1: Document Docs2.txt, Score: 0.6457\n",
            "Rank 2: Document Docs18.txt, Score: 0.4226\n",
            "Rank 3: Document Docs17.txt, Score: 0.4210\n",
            "\n",
            "Query: Tesco website down\n",
            "Rank 1: Document Docs18.txt, Score: 0.8464\n",
            "Rank 2: Document Docs17.txt, Score: 0.8432\n",
            "Rank 3: Document Docs19.txt, Score: 0.8399\n",
            "\n",
            "Query: Xbox download stuck\n",
            "Rank 1: Document Docs7.txt, Score: 1.5575\n",
            "Rank 2: Document Docs9.txt, Score: 0.0862\n",
            "Rank 3: Document Docs8.txt, Score: 0.0814\n",
            "\n",
            "Query: Netflix buffering\n",
            "Rank 1: Document Docs3.txt, Score: 0.5787\n",
            "Rank 2: Document Docs8.txt, Score: 0.3748\n",
            "Rank 3: Document Docs12.txt, Score: 0.1462\n",
            "\n",
            "Query: Amazon missing delivery\n",
            "Rank 1: Document Docs11.txt, Score: 0.7083\n",
            "Rank 2: Document Docs2.txt, Score: 0.4281\n",
            "Rank 3: Document Docs18.txt, Score: 0.0467\n",
            "\n",
            "Query: Samsung TV black screen\n",
            "Rank 1: Document Docs12.txt, Score: 1.0335\n",
            "Rank 2: Document Docs8.txt, Score: 0.0472\n",
            "Rank 3: Document Docs18.txt, Score: 0.0331\n",
            "\n",
            "Query: Spotify shuffle problem\n",
            "Rank 1: Document Docs13.txt, Score: 0.3076\n",
            "Rank 2: Document Docs18.txt, Score: 0.0523\n",
            "Rank 3: Document Docs19.txt, Score: 0.0519\n",
            "\n",
            "Query: UberEats wrong order\n",
            "Rank 1: Document Docs14.txt, Score: 1.2353\n",
            "Rank 2: Document Docs13.txt, Score: 0.0686\n",
            "Rank 3: Document Docs11.txt, Score: 0.0663\n",
            "\n",
            "Query: Tesla Supercharger error\n",
            "Rank 1: Document Docs15.txt, Score: 1.2186\n",
            "Rank 2: Document Docs18.txt, Score: 0.2110\n",
            "Rank 3: Document Docs17.txt, Score: 0.2102\n",
            "\n",
            "Query: Google Photos storage\n",
            "Rank 1: Document Docs16.txt, Score: 1.2246\n",
            "Rank 2: Document Docs20.txt, Score: 0.1376\n",
            "Rank 3: Document Docs18.txt, Score: 0.0702\n",
            "\n",
            "Query: Zoom audio issue\n",
            "Rank 1: Document Docs17.txt, Score: 0.2079\n",
            "Rank 2: Document Docs10.txt, Score: 0.0583\n",
            "Rank 3: Document Docs2.txt, Score: 0.0531\n",
            "\n",
            "Query: AirPods connection issue\n",
            "Rank 1: Document Docs18.txt, Score: 0.1850\n",
            "Rank 2: Document Docs8.txt, Score: 0.0358\n",
            "Rank 3: Document Docs10.txt, Score: 0.0291\n",
            "\n",
            "Query: Fitbit sync problem\n",
            "Rank 1: Document Docs19.txt, Score: 0.3116\n",
            "Rank 2: Document Docs18.txt, Score: 0.1047\n",
            "Rank 3: Document Docs13.txt, Score: 0.1027\n",
            "\n",
            "Query: YouTube HD playback\n",
            "Rank 1: Document Docs20.txt, Score: 0.8269\n",
            "Rank 2: Document Docs12.txt, Score: 0.2756\n",
            "Rank 3: Document Docs18.txt, Score: 0.1405\n",
            "\n",
            "Query: Uber cancellation fees\n",
            "Rank 1: Document Docs9.txt, Score: 0.6916\n",
            "Rank 2: Document Docs6.txt, Score: 0.3471\n",
            "Rank 3: Document Docs18.txt, Score: 0.1405\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O7HnTxvZbHY6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}